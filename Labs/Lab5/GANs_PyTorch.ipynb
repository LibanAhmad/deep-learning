{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMFIguHg7wY3"
      },
      "source": [
        "# Generative Adversarial Networks (GANs)\n",
        "\n",
        "So far all the applications of neural networks that we have explored have been **discriminative models** that take an input and are trained to produce a labeled output. In this assignment, we will  build **generative models** using neural networks. Specifically, we will learn how to build models which generate novel images that resemble a set of training images.\n",
        "\n",
        "### What is a GAN?\n",
        "\n",
        "In a GAN, we build two different neural networks. Our first network is a traditional classification network, called the **discriminator**. We will train the discriminator to take images, and classify them as being real (belonging to the training set) or fake (not present in the training set). Our other network, called the **generator**, will take random noise as input and transform it using a neural network to produce images. The goal of the generator is to fool the discriminator into thinking the images it produced are real.\n",
        "\n",
        "We can think of this back and forth process of the generator ($G$) trying to fool the discriminator ($D$), and the discriminator trying to correctly classify real (1) vs. fake (0) as a minimax game:\n",
        "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "where $z \\sim p(z)$ are the random noise samples, $G(z)$ are the generated images using the neural network generator $G$, and $D$ is the output of the discriminator, specifying the probability of an input being real.\n",
        "\n",
        "To optimize this minimax game, we will aternate between taking gradient *descent* steps on the objective for $G$, and gradient *ascent* steps on the objective for $D$:\n",
        "1. update the **generator** ($G$) to minimize the probability of the __discriminator making the correct choice__.\n",
        "2. update the **discriminator** ($D$) to maximize the probability of the __discriminator making the correct choice__.\n",
        "\n",
        "\n",
        "In this assignment, we will alternate the following updates:\n",
        "1. Update the generator ($G$) to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
        "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "2. Update the discriminator ($D$), to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
        "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oewOFDc7wZB"
      },
      "source": [
        "## Import Packages and define necessary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VE-v_E-C7wZD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "def show_images(images):\n",
        "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqrqT7r7wZG"
      },
      "source": [
        "## Dataset\n",
        "we will be working on the MNIST dataset, which is 60,000 training and 10,000 test images.\n",
        "You need complete the code to create dataset and data loader. Use torchvision to do this. for transform only use the ToTensor()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "VarZXCrN7wZH",
        "outputId": "25a443c9-47da-415b-9a2f-0215e9d89177",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEKUlEQVR4nO2cSyh9URTGv/snA/LIhFISA0IyQUlJkhQDj4kyIiPKyMTMgJTHQAyMlIkMPSYMvAZKyWOizMnM+53Hf3SWLRfnXvc4a/P9Rl+rfc/Zt6+1zrl773UDLy8vLyC+8s/vCRCaoAKaoACaoACaoACaoACaoACaoACaoIBotwMDgYCX8/iVuF2MYCYogCYogCYogCYogCYogCYogCYogCYogCYogCYogCYogCYogCYowPUqqgaioqJEJyYmfjq2s7NTdGxsLAAgOztbYh0dHaKHhoZENzc3AwDu7u4kNjAwILq3tzfUaX8JM0EBvmdCenq66JiYGABAaWmpxMrKykQnJSWJbmxsDPleh4eHokdHR0XX19eLvry8BADs7e1JbG1tLeR7hQIzQQE0QQEBtweCI7m9WVhYKHp5eVn0Vw/bcHl+fgYAtLa2Suzq6iro2OPjYwDA6empxA4ODsK6L7c3LYImKMCXcpScnCx6c3NTdGZmZsjXMj9/dnYmuqKiQvTDwwMA78rdR7AcWQRNUIAvP9ZOTk5Ed3d3i66trQUA7OzsSMz8UWWyu7sLAKiqqpLY9fW16Ly8PNFdXV3fm7DHMBMU4MuD+SMSEhIAvC4dAMDExITotrY20S0tLQCA6elpz+cVLnwwWwRNUIDvq6gmFxcX72Ln5+dBx7a3twMAZmZmJOYsT9gGM0EBNEEBqt6OghEXFyd6fn5edHl5OQCgpqZGYktLSz83MRfw7cgiaIIC1Jcjk6ysLNHb29sA3q6crqysiN7a2hI9Pj4OwH15iBQsRxZhVSaYOCckJicnJRYfHx90bE9PDwBgampKYs42ppcwEyyCJijA2nLkkJ+fL3pkZER0ZWXlu7HmimxfX5/oo6MjT+bGcmQRNEEB1pcjE/Osal1dnWjnDcr8DuahM3OLNJKwHFkETVDArypHH3F/fw8AiI5+3cN6fHwUXV1dLXp1dTVi92U5sghV25vhUFBQILqpqUl0UVGRaDMDHPb390Wvr697NDt3MBMUQBMUYFU5Mrsvne7MhoYGiaWmpn76+aenJ9HmKqrfpzSYCQqgCQpQWY7MsuI0dwNvG8QzMjJcX8/Z6jRXTufm5r4xw8jCTFAATVCA7+UoJSVFdG5uLgBgbGxMYjk5Oa6vZfavDQ4Oip6dnQXg/1vQRzATFPBjmWB2bJrbjGZjeSjdmxsbGwCA4eFhiS0uLoq+vb0NZ5q+wExQAE1QgCflqKSkRLTTnVlcXCyxtLQ019e6ubkRbXZy9vf3A3jbsWkrzAQF0AQFeFKOzH/SMnUwzM2VhYUFAG+3Hs23H/ME9m+CmaAAmqCAP3Hawi942sIiaIICaIICaIICaIICaIICaIICXC9b/HQj9l+CmaAAmqAAmqAAmqAAmqAAmqAAmqAAmqAAmqCA/2NEM/swNrVUAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "NUM_TRAIN = 50000\n",
        "NUM_VAL = 5000\n",
        "\n",
        "NOISE_DIM = 96\n",
        "batch_size = 128\n",
        "\n",
        "## Start Code Here ##\n",
        "# mnist train dataset\n",
        "mnist_train =\n",
        "# create train dataloader\n",
        "loader_train =\n",
        "# msnit test dataset\n",
        "mnist_val =\n",
        "# create mnist dataloader\n",
        "loader_val =\n",
        "## End code here###\n",
        "iter_mnist_train = iter(mnist_train)\n",
        "imgs = next(iter_mnist_train)[0]\n",
        "show_images(imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gctGat3y7wZJ"
      },
      "source": [
        "## Random Noise\n",
        "Generate uniform noise from -1 to 1 with shape `[batch_size, dim]`.\n",
        "\n",
        "Hint: use `torch.rand`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvBOMIyj7wZK"
      },
      "outputs": [],
      "source": [
        "def sample_noise(batch_size, dim):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Tensor of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    ## start code here ###\n",
        "    return\n",
        "    ## end code here ##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JWLovzB7wZL"
      },
      "source": [
        "Make sure noise is the correct shape and type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGoHVHQh7wZO"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Recall our Flatten operation from previous notebooks... this time we also provide an Unflatten, which you might want to use when implementing the generator. We also provide a weight initializer (and call it for you) that uses Xavier initialization instead of PyTorch's uniform default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1HQG6iCE7wZO"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    \"\"\"\n",
        "    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n",
        "    to produce an output of shape (N, C, H, W).\n",
        "    \"\"\"\n",
        "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "    def forward(self, x):\n",
        "        return x.view(self.N, self.C, self.H, self.W)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozbx7d1o7wZP"
      },
      "source": [
        "## CPU / GPU\n",
        "By default all code will run on CPU. GPUs are not needed for this assignment, but will help you to train your models faster. If you do want to run the code on a GPU, then change the `dtype` variable in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fdJHEpzg7wZQ"
      },
      "outputs": [],
      "source": [
        "dtype = torch.FloatTensor\n",
        "#dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSglPOZy7wZQ"
      },
      "source": [
        "# Discriminator\n",
        "Our first step is to build a discriminator. Fill in the architecture as part of the `nn.Sequential` constructor in the function below. All fully connected layers should include bias terms. The architecture is:\n",
        " * Flatten layer to convert the image to vector\n",
        " * Fully connected layer with input size 784 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input_size 256 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input size 256 and output size 1\n",
        "\n",
        "Recall that the Leaky ReLU nonlinearity computes $f(x) = \\max(\\alpha x, x)$ for some fixed constant $\\alpha$; for the LeakyReLU nonlinearities in the architecture above we set $\\alpha=0.01$.\n",
        "\n",
        "The output of the discriminator should have shape `[batch_size, 1]`, and contain real numbers corresponding to the scores that each of the `batch_size` inputs is a real image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s-nop0L87wZR"
      },
      "outputs": [],
      "source": [
        "def discriminator():\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "    model = nn.Sequential(\n",
        "        ## Start Code Here #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ## End Code Here ##\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZP3wnfK7wZS"
      },
      "source": [
        "# Generator\n",
        "Now to build the generator network:\n",
        " * Fully connected layer from noise_dim to 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with size 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with size 784\n",
        " * `TanH` (to clip the image to be in the range of [-1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YqWEC3L27wZS"
      },
      "outputs": [],
      "source": [
        "def generator(noise_dim=NOISE_DIM):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "    model = nn.Sequential(\n",
        "       ## Start Code Here ##\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       ## End Code Here ##\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK62Dgdo7wZT"
      },
      "source": [
        "# GAN Loss\n",
        "\n",
        "Compute the generator and discriminator loss. The generator loss is:\n",
        "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "and the discriminator loss is:\n",
        "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vYdqSMI67wZU"
      },
      "outputs": [],
      "source": [
        "## Start Code Here ##\n",
        "# create a object of binary cross entropy loss from nn.BCELoss.\n",
        "bce_loss =\n",
        "## End Code Here ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SOJ5EWzx7wZV"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(logits_real, logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the discriminator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_real: PyTorch Variable of shape (N,) giving scores for the real data.\n",
        "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Variable containing (scalar) the loss for the discriminator.\n",
        "    \"\"\"\n",
        "    # Target label vector, the discriminator should be aiming\n",
        "    ## Start Code Here ##\n",
        "    # We know the truth label for discriminator is 0 (for fake data) and 1 ( for real data)\n",
        "    # create a Varaiable by using Variable class in torch.autograd that contain the 1 label with the same shape of the logits_real\n",
        "    true_labels =\n",
        "    ## End Code Here ##\n",
        "    # Discriminator loss has 2 parts: how well it classifies real images and how well it\n",
        "    # classifies fake images.\n",
        "    ## Start Code Here ##\n",
        "    # use bce_loss to find the loss function for real image and fake image. For fake image loss you need to compare logits_fake with 0(truth label for fake image)\n",
        "    real_image_loss =\n",
        "    fake_image_loss =\n",
        "\n",
        "    # Add to loss terms to made the full loss\n",
        "    loss =\n",
        "    ## End Code Here ##\n",
        "    return loss\n",
        "\n",
        "def generator_loss(logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the generator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Variable containing the (scalar) loss for the generator.\n",
        "    \"\"\"\n",
        "    # Generator is trying to make the discriminator output 1 for all its images.\n",
        "    # So we create a 'target' label vector of ones for computing generator loss.\n",
        "    ## Start Code Here\n",
        "    # use Variable class in torch.autograd to cerate the label for generator loss\n",
        "    true_labels =\n",
        "\n",
        "    # Compute the generator loss compraing\n",
        "    ## use bce_loss to find the loss value for generator\n",
        "    loss =\n",
        "\n",
        "    ## End code Here\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-t3MkAp7wZW"
      },
      "source": [
        "# Optimizing our loss\n",
        "Make a function that returns an `optim.Adam` optimizer for the given model with a 1e-3 learning rate, beta1=0.5, beta2=0.999. You'll use this to construct optimizers for the generators and discriminators for the rest of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yKZBUDCm7wZX"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model):\n",
        "    \"\"\"\n",
        "    Construct and return an Adam optimizer for the model with learning rate 1e-3,\n",
        "    beta1=0.5, and beta2=0.999.\n",
        "\n",
        "    Input:\n",
        "    - model: A PyTorch model that we want to optimize.\n",
        "\n",
        "    Returns:\n",
        "    - An Adam optimizer for the model with the desired hyperparameters.\n",
        "    \"\"\"\n",
        "    ### Start Code Here\n",
        "    # Create a Adam optimizer with lr=0.001, betas=(0.5, 0.999) hyper parameters\n",
        "    optimizer =\n",
        "    ## End Code Here\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko80FnTy7wZX"
      },
      "source": [
        "# Training a GAN!\n",
        "\n",
        "We provide you the main training loop... you won't need to change this function, but we encourage you to read through and understand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q6yijXfb7wZX"
      },
      "outputs": [],
      "source": [
        "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, show_every=250,\n",
        "              batch_size=128, noise_size=96, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train a GAN!\n",
        "\n",
        "    Inputs:\n",
        "    - D, G: PyTorch models for the discriminator and generator\n",
        "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
        "      discriminator and generator.\n",
        "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
        "      discriminator loss, respectively.\n",
        "    - show_every: Show samples after every show_every iterations.\n",
        "    - batch_size: Batch size to use for training.\n",
        "    - noise_size: Dimension of the noise to use as input to the generator.\n",
        "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
        "    \"\"\"\n",
        "    iter_count = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x, _ in loader_train:\n",
        "            if len(x) != batch_size:\n",
        "                continue\n",
        "            D_solver.zero_grad()\n",
        "            real_data = Variable(x).type(dtype)\n",
        "            logits_real = D(2 * (real_data - 0.5)).type(dtype)\n",
        "\n",
        "            g_fake_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
        "            fake_images = G(g_fake_seed).detach()\n",
        "            logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
        "            d_total_error.backward()\n",
        "            D_solver.step()\n",
        "\n",
        "            G_solver.zero_grad()\n",
        "            g_fake_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
        "            fake_images = G(g_fake_seed)\n",
        "\n",
        "            gen_logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "            g_error = generator_loss(gen_logits_fake)\n",
        "            g_error.backward()\n",
        "            G_solver.step()\n",
        "\n",
        "            if (iter_count % show_every == 0):\n",
        "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(), g_error.item()))\n",
        "                imgs_numpy = fake_images.data.cpu().numpy()\n",
        "                fig = show_images(imgs_numpy[0:16])\n",
        "                plt.show()\n",
        "                print()\n",
        "            iter_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGn_ZwIm7wZX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "D = discriminator().type(dtype)\n",
        "G = generator().type(dtype)\n",
        "\n",
        "D_solver = get_optimizer(D)\n",
        "G_solver = get_optimizer(G)\n",
        "\n",
        "# Run it!\n",
        "run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K384GaSH7wZY"
      },
      "source": [
        "# Least Squares GAN\n",
        "We'll now look at [Least Squares GAN](https://arxiv.org/abs/1611.04076), a newer, more stable alernative to the original GAN loss function. For this part, all we have to do is change the loss function and retrain the model. We'll implement equation (9) in the paper, with the generator loss:\n",
        "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
        "and the discriminator loss:\n",
        "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
        "\n",
        "\n",
        "**HINTS**: Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing. When plugging in for $D(x)$ and $D(G(z))$ use the direct output from the discriminator (`scores_real` and `scores_fake`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TYDQ9dHr7wZY"
      },
      "outputs": [],
      "source": [
        "def ls_discriminator_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Compute the Least-Squares GAN loss for the discriminator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_real: PyTorch Variable of shape (N,) giving scores for the real data.\n",
        "    - scores_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Variable containing the loss.\n",
        "    \"\"\"\n",
        "    true_labels = Variable(torch.ones(scores_real.size())).type(dtype)\n",
        "    ## Start Code Here\n",
        "    fake_image_loss =\n",
        "    real_image_loss =\n",
        "    ## End Code Here\n",
        "    loss = 0.5 * fake_image_loss + 0.5 * real_image_loss\n",
        "    return loss\n",
        "\n",
        "def ls_generator_loss(scores_fake):\n",
        "    \"\"\"\n",
        "    Computes the Least-Squares GAN loss for the generator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Variable containing the loss.\n",
        "    \"\"\"\n",
        "    true_labels = Variable(torch.ones(scores_fake.size())).type(dtype)\n",
        "    ## Start Code Here\n",
        "    loss =\n",
        "\n",
        "    ## End Code Here\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mggo18TMTOHp"
      },
      "outputs": [],
      "source": [
        "D_LS = discriminator().type(dtype)\n",
        "G_LS = generator().type(dtype)\n",
        "\n",
        "D_LS_solver = get_optimizer(D_LS)\n",
        "G_LS_solver = get_optimizer(G_LS)\n",
        "\n",
        "run_a_gan(D_LS, G_LS, D_LS_solver, G_LS_solver, ls_discriminator_loss, ls_generator_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9iM4VfK7wZa"
      },
      "source": [
        "# Deeply Convolutional GANs\n",
        "#### Discriminator\n",
        "We will use the following discriminator\n",
        "* Conv2D: 32 Filters, 5x5, Stride 1\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Conv2D: 64 Filters, 5x5, Stride 1\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Flatten\n",
        "* Fully Connected with output size 4 x 4 x 64\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Fully Connected with output size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0xFSpxW7wZb",
        "outputId": "bdbddebe-cc53-401c-ab5c-93ee5f174cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100352\n",
            "None\n",
            "torch.Size([128, 1])\n"
          ]
        }
      ],
      "source": [
        "def build_dc_classifier():\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model for the DCGAN discriminator implementing\n",
        "    the architecture above.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        ## Start Code Here\n",
        "\n",
        "\n",
        "\n",
        "        ## End Code Here\n",
        "    )\n",
        "\n",
        "iter_loader_train = iter(loader_train)\n",
        "data = Variable(next(iter_loader_train)[0]).type(dtype)\n",
        "print(print(batch_size * 1 * 28* 28))\n",
        "b = build_dc_classifier().type(dtype)\n",
        "out = b(data)\n",
        "print(out.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdGFEcqA7wZc"
      },
      "source": [
        "#### Generator\n",
        "For the generator we use following architecture\n",
        "* Fully connected with output size 1024\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Fully connected with output size 7 x 7 x 128\n",
        "* ReLU\n",
        "* BatchNorm\n",
        "* Reshape into Image Tensor of shape 7, 7, 128\n",
        "* Conv2D^T (Transpose): 64 filters of 4x4, stride 2, 'same' padding\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Conv2D^T (Transpose): 1 filter of 4x4, stride 2, 'same' padding\n",
        "* `TanH`\n",
        "* Should have a 28x28x1 image, reshape back into 784 vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwQEwSur7wZc",
        "outputId": "ee58ee78-035d-4f33-a947-60f079ed7e9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_dc_generator(noise_dim=NOISE_DIM):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the DCGAN generator using\n",
        "    the architecture described above.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "       ## Start Code Here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       ## End Code Here\n",
        "    )\n",
        "\n",
        "test_g_gan = build_dc_generator().type(dtype)\n",
        "test_g_gan.apply(initialize_weights)\n",
        "\n",
        "fake_seed = Variable(torch.randn(batch_size, NOISE_DIM)).type(dtype)\n",
        "fake_images = test_g_gan.forward(fake_seed)\n",
        "fake_images.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T82qYKiF1j3"
      },
      "outputs": [],
      "source": [
        "D_DC = build_dc_classifier().type(dtype)\n",
        "D_DC.apply(initialize_weights)\n",
        "G_DC = build_dc_generator().type(dtype)\n",
        "G_DC.apply(initialize_weights)\n",
        "\n",
        "D_DC_solver = get_optimizer(D_DC)\n",
        "G_DC_solver = get_optimizer(G_DC)\n",
        "\n",
        "run_a_gan(D_DC, G_DC, D_DC_solver, G_DC_solver, discriminator_loss, generator_loss) #, num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mXh_hwl7wZe"
      },
      "source": [
        "## Tasks for report:\n",
        "1) You need to compare implemented loss functions in the report.\n",
        "2) Write the inference code for using a trained generator to generate an image and then show it in this notebook. Put that inference code in the report.\n",
        "3) Generate images using the written inference code for all the methods above and put them in your report with comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gDM53rmTOHq"
      },
      "source": [
        "# Lab Report Questions\n",
        "\n",
        "Please answer the following questions in your lab report. Your answers should be based on your observations during training. The viva in the lab will also include the concepts discussed in the questions below so prepare well.\n",
        "\n",
        "### 1. Architecture Comparison: Dense vs. Convolutional\n",
        "**Question:** Compare the generated image quality between the first GAN (using fully connected layers) and the DCGAN (using convolutional layers).\n",
        "* **Visual Analysis:** Which model produced sharper, more coherent digits?\n",
        "* **Conceptual:** Discuss how layers like `Conv2DTranspose` and the preservation of spatial structure contribute to this difference.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Analyzing Loss Functions: Standard vs. Least Squares\n",
        "**Question:** You implemented both the standard Minimax Loss and the Least Squares Loss (LSGAN).\n",
        "* **Theoretical:** What specific problem with the standard GAN loss (sigmoid cross-entropy) does the Least Squares GAN attempt to solve? (Hint: Consider the gradient magnitude when the discriminator is very confident).\n",
        "* **Observation:** Did you notice a difference in training stability or the quality of results between the two loss functions in your experiments?\n",
        "\n",
        "---\n",
        "\n",
        "### 3. The \"Minimax\" Dynamic\n",
        "**Question:** In the `run_a_gan` function, the discriminator and generator are updated in an alternating fashion.\n",
        "* **Scenario:** Suppose the Discriminator becomes \"too perfect\" very early in training (i.e., its loss drops to nearly 0 immediately). Why is this actually *bad* for the training of the Generator?\n",
        "* **Mechanics:** Explain how the Generator learns. If the Discriminator outputs a probability of exactly 0.0 for all fake images, what happens to the gradients flowing back to the Generator?\n",
        "---\n",
        "\n",
        "### 4. Latent Space Interpolation\n",
        "**Question:** Using the inference code you wrote for the final task, perform a \"Latent Space Interpolation\":\n",
        "1. Sample two random noise vectors, $z_1$ and $z_2$.\n",
        "2. Create 5-7 intermediate vectors using linear interpolation: $z_{new} = \\alpha \\cdot z_1 + (1-\\alpha) \\cdot z_2$ where $\\alpha$ goes from 0 to 1.\n",
        "3. Feed these vectors into your trained Generator and display the resulting strip of images.\n",
        "\n",
        "**Report:** Do the digits morph smoothly from one number to another (e.g., a 7 slowly turning into a 9), or do they change abruptly? What does this imply about whether the network has learned a meaningful continuous representation of the data?\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Mode Collapse and Diversity\n",
        "**Question:** A common failure mode in GANs is \"Mode Collapse.\"\n",
        "* **Definition:** Define Mode Collapse in your own words.\n",
        "* **Observation:** Look at a batch of 16 images generated by your best model. Is there a good variety of digits (0â€“9), or does the model seem to prefer generating only specific numbers?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}